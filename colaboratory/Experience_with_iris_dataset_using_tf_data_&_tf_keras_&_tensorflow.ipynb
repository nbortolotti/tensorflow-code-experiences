{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experience with iris dataset using tf.data & tf.keras & tensorflow.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbortolotti/tensorflow-experiences/blob/master/colaboratory/Experience_with_iris_dataset_using_tf_data_%26_tf_keras_%26_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIE-PtXxaZwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DYu_zGnvWXj",
        "colab_type": "text"
      },
      "source": [
        "*tested version TF 2.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JatG0ZNHOBd8",
        "colab_type": "text"
      },
      "source": [
        "# Experience with iris dataset using tf.keras & tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0a-vcttI8f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibZfNz2iRFIz",
        "colab_type": "text"
      },
      "source": [
        "## Data download and dataset creation witout tf.data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMgSBFkmu5rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "test_ds_url = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "ds_columns = ['SepalLength', 'SepalWidth','PetalLength', 'PetalWidth', 'Plants']\n",
        "species = np.array(['Setosa', 'Versicolor', 'Virginica'], dtype=np.object)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZP9j6sJ1a6u",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9UHLPUqubG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories='Plants'\n",
        "\n",
        "train_path = tf.keras.utils.get_file(train_ds_url.split('/')[-1], train_ds_url)\n",
        "test_path = tf.keras.utils.get_file(test_ds_url.split('/')[-1], test_ds_url)\n",
        "    \n",
        "train = pd.read_csv(train_path, names=ds_columns, header=0)\n",
        "train_plantfeatures, train_categories = train, train.pop(categories)\n",
        "\n",
        "test = pd.read_csv(test_path, names=ds_columns, header=0)\n",
        "test_plantfeatures, test_categories = test, test.pop(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIUq1ccKH4F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_plantfeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFOHjjKaS6kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_categories.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy-yiFDiReOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_categorical = tf.keras.utils.to_categorical(train_categories, num_classes=3)\n",
        "y_categorical_test = tf.keras.utils.to_categorical(test_categories, num_classes=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXxeXsEIpRCT",
        "colab_type": "text"
      },
      "source": [
        "##  Build  the Dataset\n",
        "from_tensor_slices\n",
        "\n",
        "To build the dataset we will use tf.data.Dataset set of elements. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbH7NGjpT6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_plantfeatures.values, y_categorical))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gj9O69fdCFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_plantfeatures.values, y_categorical_test))\n",
        "dataset_test = dataset_test.batch(32)\n",
        "dataset_test = dataset_test.shuffle(1000)\n",
        "dataset_test = dataset_test.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "botE10MRRR4Y",
        "colab_type": "text"
      },
      "source": [
        "## Build  the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GboZlVonPAPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(16, input_dim=4),\n",
        "  tf.keras.layers.Dense(3, activation=tf.nn.softmax),\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJDJFdpJ3WsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydyf8tTawqSb",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgM1M4HhwpWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(dataset, steps_per_epoch=32, epochs=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9S_jNi9SYyW",
        "colab_type": "text"
      },
      "source": [
        "## Eval the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PYDj5XnwJUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(dataset_test, steps=32)\n",
        "\n",
        "print(\"loss:%f\"% (loss))\n",
        "print(\"accuracy: %f\"%   (accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3elJjo4epBQ",
        "colab_type": "text"
      },
      "source": [
        "## Use the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZmCpwEFfJrE",
        "colab_type": "text"
      },
      "source": [
        "If you need to test another specie, you can modify the **new_specie** array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3cZF27oeXDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_specie = np.array([7.9,3.8,6.4,2.0])\n",
        "predition = np.around(model.predict(np.expand_dims(new_specie, axis=0))).astype(np.int)[0]\n",
        "print(\"This species should be %s\" % species[predition.astype(np.bool)][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i9-9ElyXGR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(np.expand_dims(new_specie, axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHpXgdil2ipR",
        "colab_type": "text"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZNFf5HbybVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3g4V4tOzC8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    \"./model/iris_model.h5\",\n",
        "    overwrite=True,\n",
        "    include_optimizer=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5y6VMkkzz90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = tf.keras.models.load_model(\"./model/iris_model.h5\")\n",
        "\n",
        "xarray2 = np.array([7.9,3.8,6.4,2.0])\n",
        "\n",
        "pred = np.around(new_model.predict(np.expand_dims(xarray2, axis=0))).astype(np.int)[0]\n",
        "\n",
        "print(pred)\n",
        "\n",
        "print(\"That means it's a %s\" % species[pred.astype(np.bool)][0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}